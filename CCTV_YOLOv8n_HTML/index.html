<!DOCTYPE html>
<html lang="zh-Hant">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI 淹水分割</title>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest/dist/tf.min.js"></script>

    <style>
        /* --- 優雅風格 (White Theme) --- */
        body {
            font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
            background-color: #ffffff;
            color: #333;
            margin: 0;
            padding: 40px;
            display: flex;
            flex-direction: column;
            align-items: center;
            min-height: 100vh;
        }

        h1 { font-weight: 300; margin-bottom: 10px; color: #2c3e50; }

        .main-container {
            width: 95%;
            max-width: 1000px;
            background: #fff;
            padding: 25px;
            border-radius: 12px;
            box-shadow: 0 4px 20px rgba(0,0,0,0.05);
            text-align: center;
        }

        .controls { margin: 20px 0; display: flex; gap: 15px; justify-content: center; }

        button, input[type="file"]::file-selector-button {
            background-color: #f8f9fa; border: 1px solid #e2e6ea; border-radius: 6px;
            padding: 10px 20px; font-size: 14px; cursor: pointer; transition: all 0.2s ease; color: #555;
        }
        button:hover, input[type="file"]::file-selector-button:hover { background-color: #e9ecef; color: #333; }
        button.primary { background-color: #333; color: #fff; border: none; }
        button.primary:hover { background-color: #555; }
        button:disabled { opacity: 0.5; cursor: not-allowed; }

        .status { margin-top: 15px; font-size: 14px; color: #666; min-height: 20px; }

        .comparison-container {
            display: flex; flex-wrap: wrap; gap: 20px; justify-content: center; margin-top: 30px;
        }

        .img-wrapper {
            flex: 1; min-width: 300px; max-width: 450px;
            display: flex; flex-direction: column; align-items: center;
        }

        .img-box {
            width: 100%; min-height: 200px;
            border: 2px dashed #eee; border-radius: 8px;
            display: flex; align-items: center; justify-content: center;
            overflow: hidden; padding: 10px; background: #fafafa;
        }

        .img-label { font-weight: bold; margin-bottom: 8px; color: #555; }

        img#preview, canvas#result-canvas {
            max-width: 100%; max-height: 250px; display: none; border-radius: 4px; object-fit: contain;
        }
        canvas#result-canvas { box-shadow: 0 2px 10px rgba(0,0,0,0.1); }
    </style>
</head>
<body>

    <div class="main-container">
        <h1>AI 淹水分割 (Auto Font Size)</h1>
        <p style="color:#888; font-size: 0.9em;">字體大小將自動適應圖片解析度</p>

        <div class="controls">
            <input type="file" id="uploadInput" accept="image/*">
            <button class="primary" id="detectBtn" onclick="runDetection()" disabled>開始分析</button>
        </div>

        <div class="status" id="statusText">等待模型載入...</div>

        <div class="comparison-container">
            <div class="img-wrapper">
                <div class="img-label">原始圖片</div>
                <div class="img-box">
                    <span id="placeholder-left" style="color: #ccc;">預覽圖</span>
                    <img id="preview" alt="Original Image" />
                </div>
            </div>

            <div class="img-wrapper">
                <div class="img-label">偵測結果</div>
                <div class="img-box">
                    <span id="placeholder-right" style="color: #ccc;">等待執行...</span>
                    <canvas id="result-canvas"></canvas>
                </div>
            </div>
        </div>
    </div>

    <script>
        // ================= 設定區 =================
        const MODEL_URL = './best_web_model/model.json';
        const MODEL_INPUT_SIZE = 320; 
        const CONFIDENCE_THRESHOLD = 0.3; 
        const IOU_THRESHOLD = 0.4;
        const LINE_THICKNESS = 2; 
        // ==========================================

        let model;
        const statusText = document.getElementById('statusText');
        const uploadInput = document.getElementById('uploadInput');
        const previewImg = document.getElementById('preview');
        const resultCanvas = document.getElementById('result-canvas');
        const detectBtn = document.getElementById('detectBtn');
        const placeholderLeft = document.getElementById('placeholder-left');
        const placeholderRight = document.getElementById('placeholder-right');

        const sigmoid = (x) => 1 / (1 + Math.exp(-x));

        async function loadModel() {
            try {
                statusText.innerText = "正在載入模型...";
                model = await tf.loadGraphModel(MODEL_URL);
                const dummy = tf.zeros([1, MODEL_INPUT_SIZE, MODEL_INPUT_SIZE, 3]);
                model.execute(dummy);
                tf.dispose(dummy);
                console.log("模型載入成功");
                statusText.innerText = "模型準備就緒，請上傳圖片。";
                detectBtn.disabled = false;
            } catch (error) {
                console.error("載入失敗:", error);
                statusText.innerText = "錯誤：無法載入模型";
            }
        }
        loadModel();

        uploadInput.addEventListener('change', (event) => {
            const file = event.target.files[0];
            if (file) {
                const reader = new FileReader();
                reader.onload = (e) => {
                    previewImg.src = e.target.result;
                    previewImg.style.display = 'block';
                    placeholderLeft.style.display = 'none';
                    resultCanvas.style.display = 'none';
                    placeholderRight.style.display = 'block';
                    statusText.innerText = "圖片已載入";
                };
                reader.readAsDataURL(file);
            }
        });

        async function runDetection() {
            if (!model || !previewImg.src) return;
            detectBtn.disabled = true;
            statusText.innerText = "正在分析...";
            
            resultCanvas.width = previewImg.naturalWidth;
            resultCanvas.height = previewImg.naturalHeight;
            const ctx = resultCanvas.getContext('2d');
            ctx.drawImage(previewImg, 0, 0, resultCanvas.width, resultCanvas.height);

            await detectAndDraw(previewImg);
            detectBtn.disabled = false;
        }

        async function detectAndDraw(imageElement) {
            const startTime = performance.now();
            const tfImg = tf.browser.fromPixels(imageElement)
                .resizeNearestNeighbor([MODEL_INPUT_SIZE, MODEL_INPUT_SIZE])
                .toFloat()
                .div(tf.scalar(255.0))
                .expandDims();

            try {
                const results = model.execute(tfImg);
                let output0, output1;
                if (Array.isArray(results)) {
                    if (results[0].shape.length === 3) {
                        output0 = results[0]; output1 = results[1];
                    } else {
                        output0 = results[1]; output1 = results[0];
                    }
                } else { console.error("輸出格式不符"); return; }

                const squeezed = output0.squeeze(); 
                const transposed = squeezed.transpose([1, 0]); 
                const boxesData = await transposed.array();

                const candidateBoxes = [];
                const candidateScores = [];
                const candidateIndices = [];

                for (let i = 0; i < boxesData.length; i++) {
                    let score = boxesData[i][4];
                    if (score > 1.0) score = sigmoid(score);

                    if (score > CONFIDENCE_THRESHOLD) {
                        const [cx, cy, w, h] = boxesData[i].slice(0, 4);
                        candidateBoxes.push([cy - h/2, cx - w/2, cy + h/2, cx + w/2]);
                        candidateScores.push(score);
                        candidateIndices.push(i);
                    }
                }

                if (candidateBoxes.length > 0) {
                    const boxesTensor = tf.tensor2d(candidateBoxes);
                    const scoresTensor = tf.tensor1d(candidateScores);
                    const selectedIndicesTensor = await tf.image.nonMaxSuppressionAsync(
                        boxesTensor, scoresTensor, 20, IOU_THRESHOLD, CONFIDENCE_THRESHOLD
                    );
                    const selectedIndicesMap = await selectedIndicesTensor.data();

                    const protoTensor = output1.squeeze();
                    const pShape = protoTensor.shape;
                    let maskMat, protoH, protoW;
                    
                    if (pShape[0] === 32) {
                        protoH = pShape[1]; protoW = pShape[2];
                        maskMat = protoTensor.reshape([32, protoH * protoW]).transpose(); 
                    } else {
                        protoH = pShape[0]; protoW = pShape[1];
                        maskMat = protoTensor.reshape([protoH * protoW, 32]);
                    }

                    const ctx = resultCanvas.getContext('2d');
                    
                    for (let i = 0; i < selectedIndicesMap.length; i++) {
                        const idxInCandidate = selectedIndicesMap[i];
                        const originalIdx = candidateIndices[idxInCandidate];
                        const score = candidateScores[idxInCandidate];

                        const data = boxesData[originalIdx];
                        const maskCoeffs = data.slice(5, 5 + 32);
                        const coeffsTensor = tf.tensor2d(maskCoeffs, [32, 1]);

                        const maskFlat = maskMat.matMul(coeffsTensor);
                        const maskActivated = tf.sigmoid(maskFlat);
                        const maskImg = maskActivated.reshape([protoH, protoW]);

                        const maskCanvas = document.createElement('canvas');
                        maskCanvas.width = protoW;
                        maskCanvas.height = protoH;
                        await tf.browser.toPixels(maskImg, maskCanvas);

                        const tempCanvas = document.createElement('canvas');
                        tempCanvas.width = resultCanvas.width;
                        tempCanvas.height = resultCanvas.height;
                        const tempCtx = tempCanvas.getContext('2d');
                        tempCtx.imageSmoothingEnabled = true;
                        tempCtx.drawImage(maskCanvas, 0, 0, tempCanvas.width, tempCanvas.height);

                        const imgData = tempCtx.getImageData(0, 0, tempCanvas.width, tempCanvas.height);
                        const pixels = imgData.data;

                        const outputData = ctx.getImageData(0, 0, resultCanvas.width, resultCanvas.height);
                        const outPixels = outputData.data;
                        const width = resultCanvas.width;
                        const height = resultCanvas.height;

                        const edgePoints = [];
                        let sumX = 0;
                        let sumY = 0;
                        let pixelCount = 0;

                        // 掃描像素
                        for (let y = 1; y < height - 1; y++) {
                            for (let x = 1; x < width - 1; x++) {
                                const idx = (y * width + x) * 4;
                                const isMask = pixels[idx] > 128;

                                if (isMask) {
                                    sumX += x;
                                    sumY += y;
                                    pixelCount++;

                                    const up = pixels[((y-1) * width + x) * 4] > 128;
                                    const down = pixels[((y+1) * width + x) * 4] > 128;
                                    const left = pixels[(y * width + (x-1)) * 4] > 128;
                                    const right = pixels[(y * width + (x+1)) * 4] > 128;

                                    if (!up || !down || !left || !right) {
                                        edgePoints.push({x, y});
                                    }
                                }
                            }
                        }

                        // 畫粗邊框
                        const thickness = LINE_THICKNESS; 
                        const r=255, g=230, b=0, a=255;
                        for (let pt of edgePoints) {
                            for (let dy = -thickness; dy <= thickness; dy++) {
                                for (let dx = -thickness; dx <= thickness; dx++) {
                                    const nx = pt.x + dx;
                                    const ny = pt.y + dy;
                                    if (nx >= 0 && nx < width && ny >= 0 && ny < height) {
                                        const nIdx = (ny * width + nx) * 4;
                                        outPixels[nIdx] = r; outPixels[nIdx+1] = g; outPixels[nIdx+2] = b; outPixels[nIdx+3] = a;
                                    }
                                }
                            }
                        }
                        ctx.putImageData(outputData, 0, 0);

                        // --- 3. 繪製中心標籤 (Auto-Scaling Font Size) ---
                        if (pixelCount > 0) {
                            const centerX = sumX / pixelCount;
                            const centerY = sumY / pixelCount;
                            
                            // 【關鍵修改】動態計算字體大小
                            // 設定為圖片寬度的 3% (Math.floor(width * 0.03))
                            // 並且設定最小值為 14px，以免小圖看不太到
                            const fontSize = Math.max(14, Math.floor(width * 0.03)); 
                            const padding = fontSize * 0.4; // Padding 也隨字體變動

                            ctx.font = `bold ${fontSize}px Arial`;
                            const labelText = `${Math.round(score * 100)}%`;
                            const textMetrics = ctx.measureText(labelText);
                            const textWidth = textMetrics.width;
                            const textHeight = fontSize; // 近似高度

                            const rectX = centerX - (textWidth / 2) - padding;
                            const rectY = centerY - (textHeight / 2) - padding;

                            // 繪製背景
                            ctx.fillStyle = "rgba(255, 230, 0, 0.9)";
                            ctx.fillRect(rectX, rectY, textWidth + padding * 2, textHeight + padding * 2);
                            
                            // 繪製文字
                            ctx.fillStyle = "#000";
                            ctx.textBaseline = "middle";
                            ctx.fillText(labelText, centerX - (textWidth / 2), centerY);
                        }

                        tf.dispose([coeffsTensor, maskFlat, maskActivated, maskImg]);
                    }

                    statusText.innerText = `分析完成！偵測到 ${selectedIndicesMap.length} 個區域。`;
                    placeholderRight.style.display = 'none';
                    resultCanvas.style.display = 'block';
                    tf.dispose([boxesTensor, scoresTensor, selectedIndicesTensor, protoTensor, maskMat]);
                } else {
                    statusText.innerText = "未偵測到任何淹水區域。";
                }
                tf.dispose([output0, output1, squeezed, transposed, tfImg]);
            } catch (err) {
                console.error(err);
                statusText.innerText = "運算錯誤：" + err.message;
                tf.dispose(tfImg);
            }
        }
    </script>
</body>
</html>
