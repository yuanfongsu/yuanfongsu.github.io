<!DOCTYPE html>
<html lang="zh-Hant">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI 淹水分割偵測 (Segmentation)</title>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest/dist/tf.min.js"></script>

    <style>
        body {
            font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
            background-color: #2c3e50; /* 改深色背景，讓黃色線條更明顯 */
            color: #ecf0f1;
            margin: 0;
            padding: 30px;
            display: flex;
            flex-direction: column;
            align-items: center;
            min-height: 100vh;
        }

        h1 { font-weight: 300; margin-bottom: 10px; color: #f1c40f; }

        .main-container {
            width: 95%;
            max-width: 1000px;
            background: #34495e;
            padding: 25px;
            border-radius: 12px;
            box-shadow: 0 10px 30px rgba(0,0,0,0.3);
            text-align: center;
        }

        .controls {
            margin: 20px 0;
            display: flex; gap: 15px; justify-content: center;
        }

        button, input[type="file"]::file-selector-button {
            background-color: #f1c40f; 
            border: none;
            border-radius: 6px; padding: 10px 25px; font-size: 15px; font-weight: bold;
            cursor: pointer; transition: all 0.2s ease; color: #2c3e50;
        }
        button:hover, input[type="file"]::file-selector-button:hover { background-color: #f39c12; }
        button:disabled { background-color: #95a5a6; cursor: not-allowed; }
        
        input[type="file"]::file-selector-button { background-color: #bdc3c7; color: #2c3e50; }

        .status { margin-top: 15px; font-size: 14px; color: #bdc3c7; min-height: 20px; }

        .img-wrapper {
            margin-top: 20px;
            position: relative;
            display: inline-block;
            border: 3px solid #7f8c8d;
            border-radius: 8px;
            overflow: hidden;
            background: #000;
            max-width: 100%;
        }

        /* 讓 Canvas 疊在圖片上面 */
        #container-box {
            position: relative;
        }
        img#preview {
            display: block;
            max-width: 100%;
            height: auto;
        }
        canvas#result-canvas {
            position: absolute;
            top: 0;
            left: 0;
            pointer-events: none; /* 讓滑鼠事件穿透 */
        }
    </style>
</head>
<body>

    <div class="main-container">
        <h1>AI 淹水區域分割 (Segmentation)</h1>
        <p style="color:#bdc3c7; font-size: 0.9em;">系統將繪製出淹水區域的黃色邊界</p>

        <div class="controls">
            <input type="file" id="uploadInput" accept="image/*">
            <button id="detectBtn" onclick="runDetection()" disabled>開始分析</button>
        </div>

        <div class="status" id="statusText">正在初始化 TensorFlow...</div>

        <div class="img-wrapper">
            <div id="container-box">
                <img id="preview" />
                <canvas id="result-canvas"></canvas>
            </div>
            <div id="placeholder" style="padding: 50px; color: #7f8c8d;">請上傳圖片</div>
        </div>
    </div>

    <script>
        // ================= 設定區 =================
        const MODEL_URL = './best_web_model/model.json';
        const MODEL_INPUT_SIZE = 320; 
        const CONFIDENCE_THRESHOLD = 0.45; // 信心門檻
        const MASK_THRESHOLD = 0.5;        // 遮罩像素門檻 (大於此值視為淹水)
        // ==========================================

        let model;
        const statusText = document.getElementById('statusText');
        const uploadInput = document.getElementById('uploadInput');
        const previewImg = document.getElementById('preview');
        const resultCanvas = document.getElementById('result-canvas');
        const detectBtn = document.getElementById('detectBtn');
        const placeholder = document.getElementById('placeholder');
        const containerBox = document.getElementById('container-box');

        // Sigmoid 函數
        const sigmoid = (x) => 1 / (1 + Math.exp(-x));

        async function loadModel() {
            try {
                statusText.innerText = "正在載入分割模型...";
                // 載入模型
                model = await tf.loadGraphModel(MODEL_URL);
                
                // 預熱模型 (Warmup)
                const dummy = tf.zeros([1, MODEL_INPUT_SIZE, MODEL_INPUT_SIZE, 3]);
                model.execute(dummy);
                tf.dispose(dummy);

                console.log("模型載入成功");
                statusText.innerText = "模型準備就緒，請上傳圖片。";
                detectBtn.disabled = false;
            } catch (error) {
                console.error("載入失敗:", error);
                statusText.innerText = "錯誤：無法載入模型，請確認路徑或檔案格式。";
                statusText.style.color = "#e74c3c";
            }
        }
        loadModel();

        uploadInput.addEventListener('change', (event) => {
            const file = event.target.files[0];
            if (file) {
                const reader = new FileReader();
                reader.onload = (e) => {
                    previewImg.src = e.target.result;
                    placeholder.style.display = 'none';
                    
                    // 清除舊 Canvas
                    const ctx = resultCanvas.getContext('2d');
                    ctx.clearRect(0, 0, resultCanvas.width, resultCanvas.height);
                    
                    statusText.innerText = "圖片已載入";
                };
                reader.readAsDataURL(file);
            }
        });

        async function runDetection() {
            if (!model || !previewImg.src) return;
            detectBtn.disabled = true;
            statusText.innerText = "正在進行語意分割分析...";
            
            // 設定 Canvas 尺寸與圖片一致
            resultCanvas.width = previewImg.naturalWidth;
            resultCanvas.height = previewImg.naturalHeight;

            await detectAndDraw(previewImg);
            detectBtn.disabled = false;
        }

        // ===============================================
        // 核心邏輯：分割遮罩處理
        // ===============================================
        async function detectAndDraw(imageElement) {
            const startTime = performance.now();

            // 1. 預處理
            const tfImg = tf.browser.fromPixels(imageElement)
                .resizeNearestNeighbor([MODEL_INPUT_SIZE, MODEL_INPUT_SIZE])
                .toFloat()
                .div(tf.scalar(255.0))
                .expandDims();

            try {
                // 2. 推論 (Inference)
                const results = model.execute(tfImg);
                
                // YOLOv8-seg 通常會回傳兩個 Tensor，或者是陣列
                // Output 0: [1, 37, 2100] -> (Box + Class + Mask Coeffs)
                // Output 1: [1, 32, 80, 80] 或 [1, 32, 160, 160] -> (Mask Prototypes)
                
                let output0, output1;
                if (Array.isArray(results)) {
                    // 通常 Prototype mask 是比較小的那個 tensor (dimension 4)
                    // 或者根據形狀判斷
                    if (results[0].shape.length === 3) {
                        output0 = results[0];
                        output1 = results[1];
                    } else {
                        output0 = results[1];
                        output1 = results[0];
                    }
                } else {
                    // 如果是 Dictionary (物件)，嘗試用常見名稱抓取
                    // 但通常 execute 回傳的是 Array 或 Tensor
                    console.error("未預期的輸出格式，請檢查 Console");
                    console.log(results);
                    return;
                }

                console.log(`Main Output: ${output0.shape}, Proto Output: ${output1.shape}`);

                // 3. 解析 Main Output (Box + Score + Coeffs)
                const squeezed = output0.squeeze(); // [37, 2100]
                const transposed = squeezed.transpose([1, 0]); // [2100, 37]
                const boxesData = await transposed.array();

                // 尋找最佳框 (Max Score)
                let maxScore = -Infinity;
                let bestIdx = -1;

                for (let i = 0; i < boxesData.length; i++) {
                    const data = boxesData[i];
                    // data[4] 是類別分數
                    let score = data[4]; 
                    if (score > 1.0) score = sigmoid(score); // 修正 Logits

                    if (score > maxScore) {
                        maxScore = score;
                        bestIdx = i;
                    }
                }

                if (bestIdx !== -1 && maxScore > CONFIDENCE_THRESHOLD) {
                    const bestData = boxesData[bestIdx];
                    
                    // 取得遮罩係數 (最後 32 個數值)
                    // data: [x, y, w, h, score, mask_coef_0 ... mask_coef_31]
                    const maskCoeffs = bestData.slice(5, 5 + 32); 
                    
                    // --- 4. 產生遮罩 (Mask Generation) ---
                    // 運算公式: Mask = Sigmoid( Proto * Coeffs )
                    
                    // 準備矩陣
                    const coeffsTensor = tf.tensor2d(maskCoeffs, [32, 1]); // [32, 1]
                    const protoTensor = output1.squeeze(); // [32, 160, 160] (假設是 160x160)
                    
                    const [protoChannels, protoH, protoW] = protoTensor.shape;
                    
                    // Reshape Proto for MatMul: [32, 160*160]
                    const protoReshaped = protoTensor.reshape([protoChannels, protoH * protoW]);
                    
                    // 矩陣相乘: [1, 32] x [32, 25600] = [1, 25600] (注意轉置)
                    // 這裡用: (Proto^T x Coeffs)^T 比較直觀，或者手動調整維度
                    // 簡單做法: [160*160, 32] x [32, 1] = [160*160, 1]
                    const protoT = protoReshaped.transpose(); // [25600, 32]
                    const maskFlat = protoT.matMul(coeffsTensor); // [25600, 1]
                    
                    // Sigmoid 激活
                    const maskActivated = tf.sigmoid(maskFlat);
                    
                    // 重塑回 2D 圖片
                    const maskImg = maskActivated.reshape([protoH, protoW]); // [160, 160]

                    // --- 5. 繪製到 Canvas ---
                    // 將 Tensor 轉為像素數據並放大到原圖尺寸
                    // 為了追求效能，我們在這裡使用 tf.browser.toPixels 畫到一個隱藏的 canvas，再放大
                    
                    const maskCanvas = document.createElement('canvas');
                    maskCanvas.width = protoW;
                    maskCanvas.height = protoH;
                    await tf.browser.toPixels(maskImg, maskCanvas); // 這會畫出黑白圖

                    const ctx = resultCanvas.getContext('2d');
                    
                    // 建立一個離屏 Canvas 來處理縮放後的遮罩
                    const tempCanvas = document.createElement('canvas');
                    tempCanvas.width = resultCanvas.width;
                    tempCanvas.height = resultCanvas.height;
                    const tempCtx = tempCanvas.getContext('2d');

                    // 將 160x160 的遮罩拉伸到原圖大小 (使用平滑插值)
                    tempCtx.imageSmoothingEnabled = true; 
                    tempCtx.drawImage(maskCanvas, 0, 0, tempCanvas.width, tempCanvas.height);
                    
                    // 取得原圖大小的像素資料
                    const imgData = tempCtx.getImageData(0, 0, tempCanvas.width, tempCanvas.height);
                    const pixels = imgData.data; // RGBA 陣列

                    // --- 6. 邊緣偵測與著色 (Edge Detection) ---
                    // 我們要直接修改 ImageData 來畫黃色邊界
                    // 演算法：如果當前像素是淹水，且上下左右有一個鄰居不是淹水，則此點為邊界

                    const width = tempCanvas.width;
                    const height = tempCanvas.height;
                    
                    // 建立一個新的 ImageData 給最終輸出
                    const outputData = ctx.createImageData(width, height);
                    const outPixels = outputData.data;

                    for (let y = 1; y < height - 1; y++) {
                        for (let x = 1; x < width - 1; x++) {
                            const i = (y * width + x) * 4;
                            // 檢查 Red 通道 (黑白圖 R=G=B)，大於 128 (0.5) 視為淹水
                            const isMask = pixels[i] > 100; 

                            if (isMask) {
                                // 檢查上下左右鄰居
                                const up = pixels[((y-1) * width + x) * 4] > 100;
                                const down = pixels[((y+1) * width + x) * 4] > 100;
                                const left = pixels[(y * width + (x-1)) * 4] > 100;
                                const right = pixels[(y * width + (x+1)) * 4] > 100;

                                if (!up || !down || !left || !right) {
                                    // 這是邊界！畫不透明黃色
                                    outPixels[i] = 255;     // R
                                    outPixels[i+1] = 215;   // G (Gold)
                                    outPixels[i+2] = 0;     // B
                                    outPixels[i+3] = 255;   // Alpha
                                } else {
                                    // 這是內部，畫半透明黃色 (或者不畫，看您需求)
                                    // 為了模仿 Colab 效果，內部稍微塗一點顏色
                                    outPixels[i] = 255;
                                    outPixels[i+1] = 215;
                                    outPixels[i+2] = 0;
                                    outPixels[i+3] = 30; // 很淡的透明度
                                }
                            }
                        }
                    }

                    // 將處理好的邊界圖畫上去
                    ctx.putImageData(outputData, 0, 0);

                    const endTime = performance.now();
                    statusText.innerText = `分析完成！信心分數: ${Math.round(maxScore*100)}% (耗時 ${Math.round(endTime - startTime)}ms)`;

                    // 清理
                    tf.dispose([coeffsTensor, protoTensor, protoReshaped, protoT, maskFlat, maskActivated, maskImg]);

                } else {
                    statusText.innerText = "未偵測到明顯的淹水區域。";
                }

                // 清理
                tf.dispose(results);
                tf.dispose(tfImg);
                tf.dispose(transposed);
                tf.dispose(squeezed);

            } catch (err) {
                console.error(err);
                statusText.innerText = "運算錯誤：" + err.message;
                tf.dispose(tfImg);
            }
        }
    </script>
</body>
</html>
